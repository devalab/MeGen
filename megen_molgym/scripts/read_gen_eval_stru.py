# Reads the structures generated by the RL model
# creates poscar files of each structures
# eg poscar/run31/eval_r31_Ga_3_1.poscar

import ase, pdb
from ase.io import read, write
import numpy as np
from pathlib import Path
import subprocess as sp
import time, pdb, os, re, itertools, datetime
from pathlib import Path


# root_dir = "/home/rohit/ssds/nnp/proj5/examples/molgym_add_one_atom/"
root_dir = "../../megen_molgym/"
all_systems = read(root_dir + "scripts/structures_eval.xyz", index=":")
# all_systems = read(root_dir + "scripts/original_Ga_2_70.xyz", index=":")

print(len(all_systems))
lens = np.array([len(i) for i in all_systems])
print(len(lens))
runs = np.array([[i] * 5000 for i in np.arange(0, 47, 5)]).reshape(1,-1)[0] #runs 0 to 11 means 110 with skip 5 means 50
# pdb.set_trace()

def make_poscar():
	run_num_size = {}
	for idx, ga_size in enumerate(lens):
		# curr_system = all_systems[idx].set_cell(30 * np.identity(3))
		num_atoms = ga_size
		try:
			tmp = str(runs[idx]) + "_Ga_" + str(ga_size)
		except IndexError:
			pdb.set_trace()
		print(tmp)
		if runs[idx] >= 0:
			if tmp in run_num_size:
				run_num_size[tmp] += 1
				write(root_dir + "scripts/poscar/no_focus_eval_22_29_35_65/run{}/eval_r{}_{}.xyz".format(runs[idx], tmp, run_num_size[tmp]), all_systems[idx])
			else:
				run_num_size[tmp] = 1
				write(root_dir + "scripts/poscar/no_focus_eval_22_29_35_65/run{}/eval_r{}_{}.xyz".format(runs[idx], tmp, run_num_size[tmp]), all_systems[idx])
	print(run_num_size)

def classify_based_on_run_and_size():
	run_num_size = {}
	stru_idx_2_runs_size_isotag = {}
	for idx, ga_size in enumerate(lens):
		curr_system = all_systems[idx].set_cell(30 * np.identity(3))
		num_atoms = ga_size
		tmp = str(runs[idx]) + "_Ga_" + str(ga_size) + "_"
		if runs[idx] > 0 and runs[idx] <= 8:
			if tmp in run_num_size:
				run_num_size[tmp] += 1
				tmp_with_iso_tag = tmp + str(run_num_size[tmp])
				stru_idx_2_runs_size_isotag[tmp_with_iso_tag] = idx
				# write(root_dir + "scripts/poscar/eval/run{}/eval_r{}_{}.poscar".format(runs[idx], tmp, run_num_size[tmp]), all_systems[idx])
			else:
				run_num_size[tmp] = 1
				tmp_with_iso_tag = tmp + str(run_num_size[tmp])
				stru_idx_2_runs_size_isotag[tmp_with_iso_tag] = idx
				# write(root_dir + "scripts/poscar/eval/run{}/eval_r{}_{}.poscar".format(runs[idx], tmp, run_num_size[tmp]), all_systems[idx])
	return stru_idx_2_runs_size_isotag

def sort_runs_size():
	tmp_list = []
	map_idx_to_run_size_isotag = classify_based_on_run_and_size()
	for k, v in map_idx_to_run_size_isotag.items():
		run, _, size, isomer_tag = k.split("_")
		tmp = [int(run), int(size), int(isomer_tag), v, 0]
		tmp_list.append(tmp)
	map_mat = np.array(tmp_list)
	ind = np.lexsort((map_mat[:,1], map_mat[:,0]))
	return map_mat[ind]

def eval_poscar(map_mat):
	for idx, row1 in enumerate(map_mat):
		same_stru = False
		tmp_list = []
		for idy, row2 in enumerate(map_mat[idx+1:,:]):
			run1, size1, iso_tag1, str_id1, _ = row1
			run2, size2, iso_tag2, str_id2, _ = row2
			if same_stru:
				break
			if run1 == run2 and size1 == size2:
				write(root_dir + "scripts/poscar/tmp/POSCAR0", all_systems[str_id1])
				write(root_dir + "scripts/poscar/tmp/POSCAR1", all_systems[str_id2])
				os.chdir("./poscar/tmp")
				output = sp.check_output(["../../../anal/maise/maise", "-cxc"]).decode("utf-8").split("\n")
				os.chdir("../../")
				tmp_list.append(float(output[-2]))
				if float(output[-2]) > 0.95:
					# print(run1, size1, iso_tag1, str_id1, float(output[-2]), "breaks")
					same_stru = True
					break
			else:
				# print("diff break or", same_stru)
				break
		if not same_stru:
			map_mat[idx,-1] = 1
			tmp_array = np.array(tmp_list)
			tmp_path = root_dir + "scripts/poscar/unique_stru/run{}/{}/".format(run1, size1)
			# Path(tmp_path).mkdir(parents=True, exist_ok=True)
			# write(tmp_path + "eval_{}.poscar".format(iso_tag1), all_systems[str_id1])
			try:
				print(run1, size1, iso_tag1, str_id1, tmp_array.max())
			except:
				print(run1, size1, iso_tag1, str_id1, 0.0000)
	# np.savetxt(root_dir + "scripts/poscar/unique_stru/map_mat_run{}.csv".format(run1), map_mat, delimiter=",")
	return map_mat[:,-1].sum()

# sorted_map_matrix = sort_runs_size()
# unique_count = eval_poscar(sorted_map_matrix)
# print(unique_count)
# map_stru_idx_to_runs_size_isotag = classify_based_on_run_and_size()
make_poscar()
